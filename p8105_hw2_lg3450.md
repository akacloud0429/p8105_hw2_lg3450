p8105_hw2_lg3450
================
Luyun Ge

# Problem1

first, clean the data in pols-month.csv

``` r
library(tidyverse)
```

``` r
pols_df = 
  # import the data
  read_csv("../fivethirtyeight_datasets/pols-month.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  # split "mon" into year/month/day in integers
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) |>
  # replace month number with month *name*
  mutate(month = month.name[month]) |>
  # create a president variable taking values gop and dem
  mutate(president = case_when(
    prez_gop == 1 ~ "gop",
    prez_dem == 1 ~ "dem"
  )) |>
  # remove prez_dem, prez_gop, day
  select(-prez_dem, -prez_gop, -day) |>
  # keep year and month leading
  relocate(year, month)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
View(pols_df)
```

second, clean the data in snp.csv

``` r
library(lubridate)
```

``` r
# import the data
snp_df = 
  read_csv("../fivethirtyeight_datasets/snp.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  # first convert date format into same format yyyy-mm-dd 
  mutate(
    date = coalesce(lubridate::ymd(date), lubridate::mdy(date)),
    # adjust two-digit years
    date = if_else(lubridate::year(date) > 2025, date - lubridate::years(100), date),
    year = lubridate::year(date),
    month_num = lubridate::month(date),
    month = month.name[month_num]
  ) |>  
  arrange(year, month_num, date) |>
  group_by(year, month) |>
  summarise(close = last(close), .groups = "drop") |>
  # prioritize year and month
  relocate(year, month)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

    ## Warning: There were 2 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `date = coalesce(lubridate::ymd(date), lubridate::mdy(date))`.
    ## Caused by warning:
    ## !  612 failed to parse.
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.

``` r
View(snp_df)
```

third, tidy the unemployment data

``` r
# import the unemployment data
unemployment_df = 
  read_csv("../fivethirtyeight_datasets/unemployment.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  # switch from "wide" to "long" format
  pivot_longer(
    cols = -year,               
    names_to = "month",
    values_to = "unemployment_rate"
  ) |>
  mutate(
    month = recode(
      month,
      "jan" = "January", "feb" = "February", "mar" = "March",
      "apr" = "April",   "may" = "May",      "jun" = "June",
      "jul" = "July",    "aug" = "August",   "sep" = "September",
      "oct" = "October", "nov" = "November", "dec" = "December"
    )
  ) |>
  relocate(year, month)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
View(unemployment_df)
```

Now join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
pols_snp_df = 
  left_join(pols_df, snp_df, by = c("year", "month"))
result_df = 
  left_join(pols_snp_df, unemployment_df, by = c("year", "month"))

View(pols_snp_df)
View(result_df)
```

``` r
names(result_df)
```

    ##  [1] "year"              "month"             "gov_gop"          
    ##  [4] "sen_gop"           "rep_gop"           "gov_dem"          
    ##  [7] "sen_dem"           "rep_dem"           "president"        
    ## [10] "close"             "unemployment_rate"

- `pols-month.csv`: This dataset contains monthly U.S. political
  composition. After cleaning, it contains integers for `year` and
  `month` (as month names), party counts (`gov_gop`, `sen_gop`,
  `rep_gop`, `gov_dem`, `sen_dem`, `rep_dem`), and `president` variable
  indicating the president’s party that month.

- `snp.csv`: This dataset contains S&P 500 index levels by date. After
  cleaning, it contains `year`, `month`, and `close`.

- `unemployment.csv`: This dataset contains monthly U.S. unemployment
  rates in a wide format. I pivoted to a tidy long format with variables
  `year`, `month` and `unemployment rate`.

- The final merged dataset has 822 rows and 11 columns, spanning years
  from 1947 to 2015. Key variables include `year`, `month`, `gov_gop`,
  `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`, `rep_dem`, `president`,
  `close`, and `unemployment rate`.

# Problem2

Read and clean the Mr. Trash Wheel sheet: first download the required
library

``` r
library(readxl)
```

then import the data from excel file

``` r
mr_df = 
  # specify the sheet, omit non-data entries
  read_excel("../202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel", 
             range = "A2:N710") |>
  janitor::clean_names() |>
  # omit rows that do not include dumpster-specific data
  drop_na(dumpster) |>
  # round and convert # of sports balls to nearest integer
  mutate(
  date  = as.Date(date),
  year  = year(date),
  month = month(date),
  month = month.name[month],
  sports_balls = as.integer(round(sports_balls)),
  # keep track of wheel type
  wheel = "Mr. Trash Wheel")
View(mr_df)
```

second clean the `Professor Trash Wheel` dataset

``` r
prof_df = 
  # specify the sheet, omit non-data entries
  read_excel("../202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel", 
             skip = 1) |>
  # clean variable names
  janitor::clean_names() |>
  # omit rows that do not include dumpster-specific data
  drop_na(dumpster) |>
  # keep track of wheel type
  mutate(
    date  = as.Date(date),
    year  = year(date),
    month = month(date),
    month = month.name[month],
    wheel = "Professor Trash Wheel")
  
View(prof_df)
```

third clean the `Gwynnda` dataset

``` r
gwynnda_df = 
  # specify the sheet, omit non-data entries
  read_excel("../202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynns Falls Trash Wheel", 
             skip = 1) |>
  # clean variable names
  janitor::clean_names() |>
  # omit rows that do not include dumpster-specific data
  drop_na(dumpster) |>
  # keep track of wheel type
  mutate(
    date  = as.Date(date),
    year  = year(date),
    month = month(date),
    month = month.name[month],
    wheel = "Gwynns Falls Trash Wheel"
  )
View(gwynnda_df)
```

combine 3 datasets

``` r
trash_all =
  bind_rows(mr_df, prof_df, gwynnda_df) |>
  relocate(dumpster, wheel, date, year, month)

View(trash_all)
```

``` r
# Total weight (tons) for Professor Trash Wheel
prof_total_weight_tons =
  trash_all |>
  filter(wheel == "Professor Trash Wheel") |>
  summarise(total = sum(weight_tons, na.rm = TRUE)) |>
  pull(total)

# Total cigarette butts collected by Gwynnda in June 2022
gwyn_cigs_jun2022 =
  trash_all |>
  filter(wheel == "Gwynns Falls Trash Wheel",
                year == 2022,
                month == "June") |>
  summarise(total = sum(cigarette_butts, na.rm = TRUE)) |>
  pull(total)
```

**Q: For available data, what was the total weight of trash collected by
Professor Trash Wheel? What was the total number of cigarette butts
collected by Gwynnda in June of 2022?**

- The cleaned and combined Trash Wheel dataset contains 1188
  observations and 15 variables; each row represents a dumpster load.

- Key variables include `wheel`, `dumpster`, `date`, `year`, `month`,
  `weight_tons`, `volume_cubic_yards`, and item counts, e.g.,
  `plastic_bottles`.

- For the available data, Professor Trash Wheel collected 282.26 tons in
  total, and Gwynnda collected 1.812^{4} cigarette butts in June 2022.

# Problem3

first we import and clean the `Zip Codes.csv`

``` r
zip_codes_df =
  read_csv("../zillow_data/Zip Codes.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  select(
    county,                          # e.g., "New York", "Kings"
    zip = contains("zip"),           # zip / zip_code / zipcode
    neighborhood
  ) |>
  mutate(
    zip    = stringr::str_pad(as.character(zip), 5, pad = "0"),
    county = stringr::str_trim(county),
    borough = case_when(
      county == "Bronx"    ~ "Bronx",
      county == "Kings"    ~ "Brooklyn",
      county == "New York" ~ "Manhattan",
      county == "Queens"   ~ "Queens",
      county == "Richmond" ~ "Staten Island",
      TRUE                 ~ county
    )
  ) |>
  select(zip, borough, neighborhood)
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
View(zip_codes_df)
```

second, we import the required library and clean the other dataset

``` r
library(stringr)
library(dplyr)
```

``` r
zip_info_df = 
  read_csv("../zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",
           na = c("NA", ".", "")) |>
  # clean variable names
  janitor::clean_names() |>

  filter(region_type == "zip", state_name == "NY") |>
  rename(zip = region_name) |>
  pivot_longer(
    cols = starts_with("x"),
    names_to  = "date_str",
    values_to = "zori"
  ) |>
  mutate(
    date_str = str_remove(date_str, "^x"),
    date_str = str_replace_all(date_str, "_", "-"),
    date  = ymd(date_str),
    year  = year(date),
    month = month(date),
    month = month.name[month],
    zip   = str_pad(as.character(zip), 5, pad = "0")
  ) |>
  group_by(zip, year, month) |>
  summarise(zori = last(zori), .groups = "drop")
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
View(zip_info_df)
```

then we join two datasets:

``` r
zori_final =
  left_join(zip_info_df, zip_codes_df, by = "zip") |>
  arrange(zip, year, match(month, month.name)) |>
  relocate(zip, borough, neighborhood, year, month, zori)
```

    ## Warning in left_join(zip_info_df, zip_codes_df, by = "zip"): Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 7541 of `x` matches multiple rows in `y`.
    ## ℹ Row 79 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.

**Briefly describe the resulting tidy dataset.** **Q: How many total
observations exist? How many unique ZIP codes are included, and how many
unique neighborhoods?**

``` r
# total number of observations (# of rows)
nrow(zori_final)
```

    ## [1] 17516

``` r
# number of unique zip codes
n_distinct(zori_final$zip)
```

    ## [1] 149

``` r
# number of unique neighborhoods
n_distinct(na.omit(zori_final$neighborhood))
```

    ## [1] 42

There are 17516 obervations exist, 149 of unique ZIP codes included, and
42 unique neighborhoods. Key variables are identifiers (`zip`,
`borough`, `neighborhood`), time (`year`, `month`), and the rent index
`zori`.

**Q: Which ZIP codes appear in the ZIP code dataset but not in the
Zillow Rental Price dataset? Using a few illustrative examples discuss
why these ZIP codes might be excluded from the Zillow dataset.**

``` r
zips_only_in_zipfile = 
  anti_join(distinct(zip_codes_df, zip), distinct(zori_final, zip), by = "zip") |>
  arrange(zip) |>
  pull(zip)
```

There are 171 ZIP codes present in the ZIP code dataset but missing from
the Zillow rental dataset. Examples include 10008, 10020, 10041. Some of
the likely reasons maybe PO-box/special-purpose ZIPs, non-residential
areas, too few listings, or boundary differences, etc.

**Rental prices fluctuated dramatically during the COVID-19 pandemic.
For all available ZIP codes, compare rental prices in January 2021 to
prices in January 2020.**

``` r
zip_label =
  zip_codes_df |>
  arrange(borough, neighborhood) |>
  group_by(zip) |>
  summarise(
    borough = first(na.omit(borough)),
    neighborhood = first(na.omit(neighborhood)),
    .groups = "drop"
  )
# join and rank the 10 largest drop
drops_tbl =
  zori_final |>
  filter(month == "January", year %in% c(2020, 2021)) |>
  select(zip, year, zori) |>
  group_by(zip, year) |>
  summarise(zori = mean(zori, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(names_from = year, values_from = zori, names_prefix = "zori_") |>
  inner_join(zip_label, by = "zip") |>
  mutate(drop = zori_2021 - zori_2020) |>
  arrange(drop) |>
  slice_head(n = 10) |>
  select(zip, borough, neighborhood, zori_2020, zori_2021, drop)
drops_tbl
```

    ## # A tibble: 10 × 6
    ##    zip   borough   neighborhood                  zori_2020 zori_2021  drop
    ##    <chr> <chr>     <chr>                             <dbl>     <dbl> <dbl>
    ##  1 10007 Manhattan Lower Manhattan                   6334.     5422. -913.
    ##  2 10069 Manhattan <NA>                              4623.     3875. -748.
    ##  3 10009 Manhattan Lower East Side                   3406.     2692. -714.
    ##  4 10016 Manhattan Gramercy Park and Murray Hill     3731.     3019. -712.
    ##  5 10001 Manhattan Chelsea and Clinton               4108.     3398. -710.
    ##  6 10002 Manhattan Lower East Side                   3645.     2935. -710.
    ##  7 10004 Manhattan Lower Manhattan                   3150.     2444. -706.
    ##  8 10038 Manhattan Lower Manhattan                   3573.     2876. -698.
    ##  9 10012 Manhattan Greenwich Village and Soho        3629.     2942. -686.
    ## 10 10010 Manhattan Gramercy Park and Murray Hill     3697.     3012. -685.

The table shows that the 10 ZIP codes with the largest rent drops from
Jan 2020 to Jan 2021 are all in Manhattan. For example, ZIP 10007 (Lower
Manhattan) fell from about 6,334 in Jan 2020 to 5,422 in Jan 2021, a
drop of over 900. The result is consistent with pandemic demand shifts
in denser areas.

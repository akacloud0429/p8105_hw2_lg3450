---
title: "p8105_hw2_lg3450"
author: Luyun Ge
output: github_document
---

# Problem1
first, clean the data in pols-month.csv
```{r message=FALSE}
library(tidyverse)
```
```{r}
pols_df = 
  # import the data
  read_csv("../fivethirtyeight_datasets/pols-month.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  # split "mon" into year/month/day in integers
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) |>
  # replace month number with month *name*
  mutate(month = month.name[month]) |>
  # create a president variable taking values gop and dem
  mutate(president = case_when(
    prez_gop == 1 ~ "gop",
    prez_dem == 1 ~ "dem"
  )) |>
  # remove prez_dem, prez_gop, day
  select(-prez_dem, -prez_gop, -day) |>
  # keep year and month leading
  relocate(year, month)
```
second, clean the data in snp.csv
```{r}
library(lubridate)
```
```{r}
# import the data
snp_df = 
  read_csv("../fivethirtyeight_datasets/snp.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  # first convert date format into same format yyyy-mm-dd 
  mutate(
    date = coalesce(lubridate::ymd(date), lubridate::mdy(date)),
    # adjust two-digit years
    date = if_else(lubridate::year(date) > 2025, date - lubridate::years(100), date),
    year = lubridate::year(date),
    month_num = lubridate::month(date),
    month = month.name[month_num]
  ) |>  
  arrange(year, month_num, date) |>
  group_by(year, month) |>
  summarise(close = last(close), .groups = "drop") |>
  # prioritize year and month
  relocate(year, month)
```
third, tidy the unemployment data
```{r}
# import the unemployment data
unemployment_df = 
  read_csv("../fivethirtyeight_datasets/unemployment.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  # switch from "wide" to "long" format
  pivot_longer(
    cols = -year,               
    names_to = "month",
    values_to = "unemployment_rate"
  ) |>
  mutate(
    month = recode(
      month,
      "jan" = "January", "feb" = "February", "mar" = "March",
      "apr" = "April",   "may" = "May",      "jun" = "June",
      "jul" = "July",    "aug" = "August",   "sep" = "September",
      "oct" = "October", "nov" = "November", "dec" = "December"
    )
  ) |>
  relocate(year, month)
```
Now join the datasets by merging snp into pols, and merging unemployment into the result.
```{r}
pols_snp_df = 
  left_join(pols_df, snp_df, by = c("year", "month"))
result_df = 
  left_join(pols_snp_df, unemployment_df, by = c("year", "month"))
```
```{r}
names(result_df)
```

* `pols-month.csv`: This dataset contains monthly U.S. political composition. After cleaning, it contains integers for `year` and `month` (as month names), party counts (`gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`, `rep_dem`), and `president` variable indicating the presidentâ€™s party that month.

* `snp.csv`: This dataset contains S&P 500 index levels by date. After cleaning, it contains `year`, `month`, and `close`.

* `unemployment.csv`: This dataset contains monthly U.S. unemployment rates in a wide format. I pivoted to a tidy long format with variables `year`, `month` and `unemployment rate`.

* The final merged dataset has `r nrow(result_df)` rows and `r ncol(result_df)` columns, spanning years from 1947 to 2015. Key variables include `year`, `month`, `gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`, `rep_dem`, `president`, `close`, and `unemployment rate`.

# Problem2 
Read and clean the Mr. Trash Wheel sheet:
first download the required library
```{r}
library(readxl)
```
then import the data from excel file
```{r}
mr_df = 
  # specify the sheet, omit non-data entries
  read_excel("../202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel", 
             range = "A2:N710") |>
  janitor::clean_names() |>
  # omit rows that do not include dumpster-specific data
  drop_na(dumpster) |>
  # round and convert # of sports balls to nearest integer
  mutate(
  date  = as.Date(date),
  year  = year(date),
  month = month(date),
  month = month.name[month],
  sports_balls = as.integer(round(sports_balls)),
  # keep track of wheel type
  wheel = "Mr. Trash Wheel")
```
second clean the ` Professor Trash Wheel` dataset
```{r}
prof_df = 
  # specify the sheet, omit non-data entries
  read_excel("../202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel", 
             skip = 1) |>
  # clean variable names
  janitor::clean_names() |>
  # omit rows that do not include dumpster-specific data
  drop_na(dumpster) |>
  # keep track of wheel type
  mutate(
    date  = as.Date(date),
    year  = year(date),
    month = month(date),
    month = month.name[month],
    wheel = "Professor Trash Wheel")
```
third clean the `Gwynnda` dataset
```{r}
gwynnda_df = 
  # specify the sheet, omit non-data entries
  read_excel("../202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynns Falls Trash Wheel", 
             skip = 1) |>
  # clean variable names
  janitor::clean_names() |>
  # omit rows that do not include dumpster-specific data
  drop_na(dumpster) |>
  # keep track of wheel type
  mutate(
    date  = as.Date(date),
    year  = year(date),
    month = month(date),
    month = month.name[month],
    wheel = "Gwynns Falls Trash Wheel"
  )
```
combine 3 datasets
```{r}
trash_all =
  bind_rows(mr_df, prof_df, gwynnda_df) |>
  relocate(dumpster, wheel, date, year, month)
```

```{r}
# Total weight (tons) for Professor Trash Wheel
prof_total_weight_tons =
  trash_all |>
  filter(wheel == "Professor Trash Wheel") |>
  summarise(total = sum(weight_tons, na.rm = TRUE)) |>
  pull(total)

# Total cigarette butts collected by Gwynnda in June 2022
gwyn_cigs_jun2022 =
  trash_all |>
  filter(wheel == "Gwynns Falls Trash Wheel",
                year == 2022,
                month == "June") |>
  summarise(total = sum(cigarette_butts, na.rm = TRUE)) |>
  pull(total)
```

**Q: For available data, what was the total weight of trash collected by Professor Trash Wheel? 
What was the total number of cigarette butts collected by Gwynnda in June of 2022?**

* The cleaned and combined Trash Wheel dataset contains `r nrow(trash_all)` observations and `r ncol(trash_all)` variables; each row represents a dumpster load. 

* Key variables include `wheel`, `dumpster`, `date`, `year`, `month`, `weight_tons`, `volume_cubic_yards`, and item counts, e.g., `plastic_bottles`. 

* For the available data, Professor Trash Wheel collected `r round(prof_total_weight_tons, 2)` tons in total, and Gwynnda collected `r round(gwyn_cigs_jun2022, 2)` cigarette butts in June 2022.


# Problem3
first we import and clean the `zip Codes.csv`
```{r}
zip_codes_df =
  read_csv("../zillow_data/zip Codes.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  select(
    county,                          # e.g., "New York", "Kings"
    zip = contains("zip"),           # zip / zip_code / zipcode
    neighborhood
  ) |>
  mutate(
    zip    = stringr::str_pad(as.character(zip), 5, pad = "0"),
    county = stringr::str_trim(county),
    borough = case_when(
      county == "Bronx"    ~ "Bronx",
      county == "Kings"    ~ "Brooklyn",
      county == "New York" ~ "Manhattan",
      county == "Queens"   ~ "Queens",
      county == "Richmond" ~ "Staten Island",
      TRUE                 ~ county
    )
  ) |>
  select(zip, borough, neighborhood)
```
second, we import the required library and clean the other dataset
```{r}
library(stringr)
library(dplyr)
```
```{r}
zip_info_df = 
  read_csv("../zillow_data/zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",
           na = c("NA", ".", "")) |>
  # clean variable names
  janitor::clean_names() |>

  filter(region_type == "zip", state_name == "NY") |>
  rename(zip = region_name) |>
  pivot_longer(
    cols = starts_with("x"),
    names_to  = "date_str",
    values_to = "zori"
  ) |>
  mutate(
    date_str = str_remove(date_str, "^x"),
    date_str = str_replace_all(date_str, "_", "-"),
    date  = ymd(date_str),
    year  = year(date),
    month = month(date),
    month = month.name[month],
    zip   = str_pad(as.character(zip), 5, pad = "0")
  ) |>
  group_by(zip, year, month) |>
  summarise(zori = last(zori), .groups = "drop")
```
then we join two datasets:
```{r}
zip_label =
  zip_codes_df |>
  arrange(borough, neighborhood) |>
  distinct(zip, .keep_all = TRUE)

zori_final =
  left_join(zip_info_df, zip_label, by = "zip") |>
  arrange(zip, year, match(month, month.name)) |>
  relocate(zip, borough, neighborhood, year, month, zori)
```
**Briefly describe the resulting tidy dataset.**
**Q: How many total observations exist? How many unique zip codes are included, and how many unique neighborhoods?**
```{r}
# total number of observations (# of rows)
nrow(zori_final)
# number of unique zip codes
n_distinct(zori_final$zip)
# number of unique neighborhoods
n_distinct(na.omit(zori_final$neighborhood))
```
There are `r nrow(zori_final)` obervations exist, `r n_distinct(zori_final$zip)` of unique zip codes included, and `r n_distinct(na.omit(zori_final$neighborhood))` unique neighborhoods.
Key variables are identifiers (`zip`, `borough`, `neighborhood`), time (`year`, `month`), and the rent index `zori`.

**Q: Which zip codes appear in the zip code dataset but not in the Zillow Rental Price dataset? Using a few illustrative examples discuss why these zip codes might be excluded from the Zillow dataset.**
```{r}
zips_only_in_zipfile = 
  anti_join(distinct(zip_codes_df, zip), distinct(zori_final, zip), by = "zip") |>
  arrange(zip) |>
  pull(zip)
```
There are `r length(zips_only_in_zipfile)` zip codes present in the zip code dataset but missing from the Zillow rental dataset. 
Examples include `r paste(head(zips_only_in_zipfile, 3), collapse = ", ")`. 
Some of the likely reasons maybe PO-box/special-purpose zips, non-residential areas, too few listings, or boundary differences, etc.

**Rental prices fluctuated dramatically during the COVID-19 pandemic. For all available zip codes, compare rental prices in January 2021 to prices in January 2020.**
```{r}
zip_label =
  zip_codes_df |>
  arrange(borough, neighborhood) |>
  group_by(zip) |>
  summarise(
    borough = first(na.omit(borough)),
    neighborhood = first(na.omit(neighborhood)),
    .groups = "drop"
  )
# join and rank the 10 largest drop
drops_tbl =
  zori_final |>
  filter(month == "January", year %in% c(2020, 2021)) |>
  select(zip, year, zori) |>
  group_by(zip, year) |>
  summarise(zori = mean(zori, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(names_from = year, values_from = zori, names_prefix = "zori_") |>
  inner_join(zip_label, by = "zip") |>
  mutate(drop = zori_2021 - zori_2020) |>
  arrange(drop) |>
  slice_head(n = 10) |>
  select(zip, borough, neighborhood, zori_2020, zori_2021, drop)
drops_tbl
```
The table shows that the 10 zip codes with the largest rent drops from Jan 2020 to Jan 2021 are all in Manhattan. For example, zip 10007 (Lower Manhattan) fell from about 6,334 in Jan 2020 to 5,422 in Jan 2021, a drop of over 900. The result is consistent with pandemic demand shifts in denser areas. 